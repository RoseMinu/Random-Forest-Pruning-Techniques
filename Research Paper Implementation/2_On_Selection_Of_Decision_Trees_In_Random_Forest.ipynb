{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1hnWHSnyALz"
   },
   "source": [
    "### Pima indian diabetes dataset\n",
    "- split the dataset into 3 parts - train, test, validation\n",
    "- define K (maximum number of features to be considered for the split)= square root of number of columns (K = M**1/2)\n",
    "- train the randomforest classifier(RF) with the data and max_features  = K\n",
    "- take a single estimator from the classifier(RF1)\n",
    "\n",
    "###### ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- create a new object of random forest classifier(RFa)\n",
    "- use the single estimator(RF1) from the previous object in the new object(RFa)\n",
    "- predict using the same dataset and compare the outputs\n",
    "\n",
    "#### conclusion : the score of the 2 models are different (RF and RFa)\n",
    "\n",
    "- the process is repeated after creating a new model estimator (RFb) combining multiple estimators from the first model created (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owPjygaOxCOZ"
   },
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from statistics import mean\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oRibKOn4xJFF",
    "outputId": "a3bfb10b-f745-48e8-a881-ef5f56dab28e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 9\n"
     ]
    }
   ],
   "source": [
    "#Data Set Reading\n",
    "# list for column headers\n",
    "names = ['Preg', 'Plas', 'Pres', 'Skin', 'Test', 'Mass', 'Pedi', 'Age', 'Class']\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",names=names)\n",
    "global N,M\n",
    "N,M=df.shape\n",
    "df.head()\n",
    "#To convert into Target and Attributes\n",
    "X_Data = df.drop(\"Class\", axis=1)\n",
    "y_Target = df[\"Class\"]\n",
    "print(N,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FW7f9zaixMAi"
   },
   "outputs": [],
   "source": [
    "def data_split():    \n",
    "    #To split the dataset into 3 parts   \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_Data, y_Target, test_size=0.4)\n",
    "    X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.5)\n",
    "    \n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgN0YrrIkC1r"
   },
   "source": [
    " ### Algorithm \n",
    " \n",
    "1) N- No of samples in dataset \n",
    "\n",
    "2) M-No of features in dataset \n",
    "\n",
    "3) K-no of features for spliting the node=SQRT(M) \n",
    "\n",
    "4) Initialize 3*L array for storing error rates - Here L=300(No of decision trees in random forest) \n",
    "\n",
    "5) Create a for loop with 10 iterations \n",
    "\n",
    "      5.1) Split dataset into 3 with .3 as training,.3 validation and .4 as testing \n",
    "      5.2)Create a random forest object and fit it with training data (No of decision trees=300,max_features=SQRT(M) \n",
    "      5.3)Create an empty RF object for SFS \n",
    "      5.4)Create a copy of already created RF object for SBS \n",
    "      5.5)Create an empty RF object for SRS \n",
    "      5.6) Create a for loop with L iterations \n",
    "      \n",
    "            5.6.1)Call the method for SFS ..Compute and store the error rates(In the 3*L array) of the newly created SFS random forest using testing dataset.  \n",
    "            5.6.2)Call the method for SFS ..Compute and store the error rates(In the 3*L array)  of the newly created SFS random forest using testing dataset.  \n",
    "            5.6.3)Call the method for SFS ..Compute and store the error rates(In the 3*L array)  of the newly created SFS random forest using testing dataset.  End both the for loop \n",
    " \n",
    " 6) Average the error rates for SFS,SBS and SRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ce1SCz19k_iE"
   },
   "source": [
    "### As per algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZUyGajc4IjA"
   },
   "outputs": [],
   "source": [
    "# number of decision trees\n",
    "global dTree = 300\n",
    "# number of features for split\n",
    "K = int(M**(1/2))\n",
    "# empty array for error rates\n",
    "error_rates_SFS, error_rates_SBS, error_rates_SRS = [], [], []\n",
    "# list to store the trees\n",
    "error_rate_SFS_10,error_rate_SBS_10,error_rate_SRS_10 = [], [], []\n",
    "\n",
    "# for loop \n",
    "for i in range(10):\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = data_split()\n",
    "    # Random forest model \n",
    "    classifier = RandomForestClassifier(n_estimators=dTree, max_features=K)\n",
    "    # fit the classifier with data\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # empty RF object for SFS\n",
    "    classifier_SFS = RandomForestClassifier()\n",
    "    error_rates_SFSMain=SFS_method(classifier_SFS,classifier)\n",
    "    error_rate_SFS_10.append(error_rates_SFSMain)\n",
    "    # copy of already created RF object for SBS\n",
    "    classifier_SBS = copy.deepcopy(classifier)\n",
    "    error_rates_SBSMain=SBS_method(classifier_SBS,classifier)\n",
    "    error_rate_SBS_10.append(error_rates_SBSMain)\n",
    "    # empty RF object for SRS\n",
    "    classifier_SRS = RandomForestClassifier()\n",
    "    error_rates_SRSMain=SRS_method(classifier_SRS,classifier)\n",
    "    error_rate_SBS_10.append(error_rates_SBSMain)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e8MtHLcelU9U"
   },
   "source": [
    "### Code for SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wd_59FFInAJe"
   },
   "outputs": [],
   "source": [
    "def SFS_method(classifier_SFS,classifier):\n",
    "    SFS_estimators = []\n",
    "    error_rates_SFS = []\n",
    "    for i in range(dTree):\n",
    "    # creating a new list for adding new trees\n",
    "        SFS_estimators.append(classifier.estimators_[i])\n",
    "        # assigning the added trees to the empty RF object created for SFS\n",
    "        classifier_SFS.estimators_ = SFS_estimators\n",
    "        # assigning the number of estimators to the SFS object\n",
    "        classifier_SFS.n_estimators = len(classifier_SFS)\n",
    "        classifier_SFS.classes_ = classifier.classes_\n",
    "        classifier_SFS.n_classes_ = classifier.n_classes_\n",
    "        classifier_SFS.n_outputs_ = classifier.n_outputs_\n",
    "        # predicting using the SFS estimator\n",
    "        y_pred = classifier_SFS.predict(X_test)\n",
    "        # calculating the accuracy score\n",
    "        acc_score = zero_one_loss(y_test, y_pred)\n",
    "        # appending score to a list\n",
    "        error_rates_SFS.append(acc_score)\n",
    "        \n",
    "    return error_rates_SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3zlxkRSYs4q"
   },
   "outputs": [],
   "source": [
    "df_SFS = pd.DataFrame(error_rate_SFS_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "CiiEGvkuY7ga",
    "outputId": "20235efb-d8f3-4bb9-f979-f597c7b6c0aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.308442</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.301948</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.262987</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.301948</td>\n",
       "      <td>0.327922</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.243506</td>\n",
       "      <td>0.230519</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.243506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.288961</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.230519</td>\n",
       "      <td>0.230519</td>\n",
       "      <td>0.243506</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230519</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.230519</td>\n",
       "      <td>0.224026</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.334416</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.305195</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.240260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.331169</td>\n",
       "      <td>0.301948</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.275974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.366883</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.314935</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.246753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.301948</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.262987</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.256494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.288961</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.262987</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.237013</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.308442</td>\n",
       "      <td>0.308442</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.308442</td>\n",
       "      <td>0.288961</td>\n",
       "      <td>0.308442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.282468</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.311688  0.308442  0.298701  0.298701  0.295455  0.301948  0.279221   \n",
       "1  0.301948  0.327922  0.269481  0.253247  0.246753  0.237013  0.243506   \n",
       "2  0.288961  0.295455  0.292208  0.285714  0.256494  0.253247  0.230519   \n",
       "3  0.334416  0.295455  0.305195  0.282468  0.266234  0.272727  0.272727   \n",
       "4  0.331169  0.301948  0.295455  0.269481  0.282468  0.269481  0.279221   \n",
       "5  0.366883  0.321429  0.314935  0.269481  0.275974  0.256494  0.275974   \n",
       "6  0.340909  0.301948  0.282468  0.256494  0.292208  0.250000  0.253247   \n",
       "7  0.285714  0.279221  0.282468  0.266234  0.295455  0.262987  0.256494   \n",
       "8  0.266234  0.285714  0.253247  0.288961  0.275974  0.272727  0.256494   \n",
       "9  0.337662  0.340909  0.321429  0.308442  0.308442  0.318182  0.311688   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.279221  0.266234  0.269481    ...     0.259740  0.262987  0.259740   \n",
       "1  0.230519  0.237013  0.243506    ...     0.237013  0.237013  0.237013   \n",
       "2  0.230519  0.243506  0.246753    ...     0.230519  0.227273  0.230519   \n",
       "3  0.275974  0.256494  0.266234    ...     0.237013  0.237013  0.240260   \n",
       "4  0.282468  0.266234  0.275974    ...     0.279221  0.279221  0.279221   \n",
       "5  0.253247  0.269481  0.240260    ...     0.246753  0.250000  0.250000   \n",
       "6  0.246753  0.250000  0.246753    ...     0.266234  0.266234  0.266234   \n",
       "7  0.259740  0.266234  0.259740    ...     0.253247  0.256494  0.259740   \n",
       "8  0.253247  0.262987  0.256494    ...     0.237013  0.233766  0.237013   \n",
       "9  0.308442  0.288961  0.308442    ...     0.279221  0.282468  0.285714   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.259740  0.259740  0.259740  0.259740  0.259740  0.259740  0.259740  \n",
       "1  0.237013  0.237013  0.237013  0.237013  0.237013  0.237013  0.237013  \n",
       "2  0.224026  0.227273  0.227273  0.227273  0.227273  0.227273  0.227273  \n",
       "3  0.240260  0.240260  0.240260  0.240260  0.240260  0.240260  0.240260  \n",
       "4  0.279221  0.279221  0.279221  0.275974  0.275974  0.275974  0.275974  \n",
       "5  0.250000  0.246753  0.246753  0.246753  0.246753  0.246753  0.246753  \n",
       "6  0.266234  0.266234  0.266234  0.266234  0.266234  0.266234  0.272727  \n",
       "7  0.259740  0.256494  0.256494  0.259740  0.256494  0.256494  0.256494  \n",
       "8  0.233766  0.233766  0.233766  0.233766  0.233766  0.233766  0.233766  \n",
       "9  0.282468  0.285714  0.282468  0.282468  0.285714  0.285714  0.285714  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for SBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBS_method(classifier_SFS,classifier):\n",
    "#     SBS_estimators = []\n",
    "#     error_rates_SBS = []\n",
    "#     for i in range(dTree):\n",
    "#     # creating a new list for adding new trees\n",
    "#         SFS_estimators.append(classifier.estimators_[i])\n",
    "#         # assigning the added trees to the empty RF object created for SFS\n",
    "#         classifier_SFS.estimators_ = SFS_estimators\n",
    "#         # assigning the number of estimators to the SFS object\n",
    "#         classifier_SFS.n_estimators = len(classifier_SFS)\n",
    "#         classifier_SFS.classes_ = classifier.classes_\n",
    "#         classifier_SFS.n_classes_ = classifier.n_classes_\n",
    "#         classifier_SFS.n_outputs_ = classifier.n_outputs_\n",
    "#         # predicting using the SFS estimator\n",
    "#         y_pred = classifier_SFS.predict(X_test)\n",
    "#         # calculating the accuracy score\n",
    "#         acc_score = zero_one_loss(y_test, y_pred)\n",
    "#         # appending score to a list\n",
    "#         error_rates_SFS.append(acc_score)\n",
    "        \n",
    "#     return error_rates_SFS\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for SRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRS_method(classifier_SFS,classifier):\n",
    "#     SRS_estimators = []\n",
    "#     error_rates_SRS = []\n",
    "#     for i in range(dTree):\n",
    "#     # creating a new list for adding new trees\n",
    "#         SFS_estimators.append(classifier.estimators_[i])\n",
    "#         # assigning the added trees to the empty RF object created for SFS\n",
    "#         classifier_SFS.estimators_ = SFS_estimators\n",
    "#         # assigning the number of estimators to the SFS object\n",
    "#         classifier_SFS.n_estimators = len(classifier_SFS)\n",
    "#         classifier_SFS.classes_ = classifier.classes_\n",
    "#         classifier_SFS.n_classes_ = classifier.n_classes_\n",
    "#         classifier_SFS.n_outputs_ = classifier.n_outputs_\n",
    "#         # predicting using the SFS estimator\n",
    "#         y_pred = classifier_SFS.predict(X_test)\n",
    "#         # calculating the accuracy score\n",
    "#         acc_score = zero_one_loss(y_test, y_pred)\n",
    "#         # appending score to a list\n",
    "#         error_rates_SFS.append(acc_score)\n",
    "        \n",
    "#     return error_rates_SFS\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "random_forest_paper.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
